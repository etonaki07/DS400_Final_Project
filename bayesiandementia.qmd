---
title: "Bayesian dementia"
authors: Faith & Elora
format: html
editor: visual
---

# Determining the strongest predictor variables and interactions for early onset dementia.

#### This is the for importing our libraries, data set, cleaning and Bayesian modeling. The document is organized with 4 sections, data cleaning, visual EDA, Bayesian modeling/testing, and then comparison and conclusion.

## 1. Libraries, dataset, and data cleaning.

#### A. libraries

```{r}
library(tidyverse)
library(bayesrules)
library(rstanarm)
library(bayesplot)
library(readr)
library(ggpubr)
```

#### B. Importing datasets and Defining variables

Source of datasets: <https://sites.wustl.edu/oasisbrains/home/oasis-1/>

```{r}
data <- read_csv("merged_oasis_data.csv")
data
```

The variables we will be using are:

-   Age: The age of different subjects with and without signs of dementia.

-   MMSE (Mini-Mental State Examination): A measure used to account for variations in head size by normalizing brain volume using total intracranial volume (TIV).

-   CDR (Clinical Dementia Rating): The CDR scale is used to stage the severity of dementia, with specific scores indicating different levels of cognitive and functional impairment. 0 = nondemented; 0.5 – very mild dementia; 1 = mild dementia; 2 = moderate dementia.  

-   nWBV (Normalized Whole Brain Volume): A 30-point questionnaire used as a screening tool to assess cognitive impairment, measuring aspects like memory, orientation, attention, and language.

#### C. Data Cleaning

```{r}
oasis <- data %>%
  select("Age", "M/F", "CDR", "nWBV", "MMSE") %>%
  na.omit() %>%
  mutate(
    dementia = ifelse(CDR == 0, 0, 1)  
  )
```

```{r}
glimpse(oasis)
```

## 2. Visual EDA/ exploring

#### These will just be some simple plots and charts to understand our variables of interest a little more before we get to modeling. It can also serve to help us make inferences before we get started.

#### A. First I have to change the CDR values from numeric to categorical because theres only 4 different values 235 rows. Ill be able to visualize my data a lot better this way.

```{r}
oasis$dementia <- factor(oasis$dementia,
                       levels= c(0,1),
                       labels= c("<0.5", ">=0.5"))
oasis <- oasis %>% 
  rename('sex' = 'M/F')
```

#### B. Now I can make some visualizations

```{r}
ggplot( data=oasis, aes(x=dementia, y=MMSE, fill=dementia)) +
  geom_boxplot()
```

```{r}
ggplot( data=oasis, aes(x=nWBV, y=Age, color=dementia)) +
 geom_point() +
  geom_smooth() +
  stat_cor()
```

```{r}
ggplot( data=oasis, aes(x=dementia, y=nWBV, fill=dementia)) +
  geom_violin(alpha=0.4)+ geom_boxplot(width=0.2)
```

```{r}
ggplot(oasis, aes(x = dementia, fill = sex)) +
  geom_bar()
```

## 3. Bayesian modeling

#### Before modeling, we need to convert dementia back to numeric (0/1) for logistic regression

```{r}
oasis_model <- oasis %>%
  mutate(
    dementia_numeric = ifelse(dementia == "<=0.5", 0, 1)
  )
```

#### A. Priors

```{r}
##chart to show distribution of dementia
ggplot(oasis_model, aes(x = dementia)) +
  geom_bar()
```

**Prior Intercept:** To get the best results, I am changing the prior intercept to 0, 1.65, since our data is between 1/2 -2/3 0 ( 0.5\<.)

**Prior slope**: For my slope prior, I have little belief and prior knowledge about what to expect, so I am keeping it weak, 0,1.

#### B. Model 1: Age + MMSE

```{r}
# Model 1: Age + MMSE
model1 <- stan_glm(
  dementia_numeric ~ Age + MMSE,
  data = oasis_model,
  family = binomial,
  prior_intercept = normal(0, 1.65),
  prior = normal(0, 1, autoscale = TRUE),
  chains = 4,
  iter = 5000*2,
  seed = 84735
)

model1
```

#### C. Model 2: Age + MMSE + nWBV (Adding Brain Volume)

```{r}
# Model 2: Age + MMSE + nWBV
model2 <- stan_glm(
  dementia_numeric ~ Age + MMSE + nWBV,
  data = oasis_model,
  family = binomial,
  prior_intercept = normal(0, 1.65),
  prior = normal(0, 1, autoscale = TRUE),
  chains = 4,
  iter = 5000*2,
  seed = 84735
)

# Summary
model2
```

#### D. Model 3: Full Model (Age + MMSE + nWBV + Sex)

```{r}
model3 <- stan_glm(
  dementia_numeric ~ Age + MMSE + nWBV + sex,
  data = oasis_model,
  family = binomial,
  prior_intercept = normal(0, 1.65),
  prior = normal(0, 1, autoscale = TRUE),
  chains = 4,
  iter = 5000*2,
  seed = 84735
)

model3
```

**Summaries of models\
**

```{r}
summary(model1)
```

**Model 1:** This model includes `Age` and `MMSE` as predictors of dementia. The estimated coefficients are very small and stable, with minimal uncertainty (standard deviations close to 0 for Age and 0.2 for MMSE). The intercept is 6.6 with a standard deviation of 6.2.

```{r}
summary(model2)
```

**Model 2:** This model adds `nWBV` as a predictor alongside Age and MMSE. The coefficient for nWBV has a median of -0.6 but a very large standard deviation of 14.7, indicating high uncertainty in its effect. Age and MMSE remain small and stable. The intercept increases slightly to 7.3 (sd 13.1). Overall, adding nWBV introduces more uncertainty into the model coefficients.

```{r}
summary(model3)
```

**Model 3:** This model further adds `sex` as a predictor in addition to Age, MMSE, and nWBV. The coefficient for sex (`sexM`) is small (0.1) with moderate uncertainty (sd 1.3). The nWBV coefficient remains highly uncertain (median -0.8, sd 14.6). Age and MMSE coefficients are stable as before. The intercept is 7.5 (sd 13.1). Adding sex does not substantially improve the model but slightly increases the number of parameters.

## 4. Comparison and conclusion

**Posterior Predictive Simulation:** We used posterior predictive simulation because the default posterior predictive check (`pp_check()`) for binary outcomes only compares 0/1 predictions and could not reveal meaningful differences between the models. Posterior predictive simulations instead show how each model changes the predicted probability of dementia, providing a clearer and more sensitive comparison of predictor importance and model behavior.

```{r}
nWBV_pred1 <- posterior_linpred(model2, newdata = oasis_model, transform = TRUE)
nWBV_pred2 <- posterior_linpred(model2, newdata = mutate(oasis_model, nWBV = mean(nWBV)), transform = TRUE)

nWBV_impact <- apply(nWBV_pred1, 2, mean) - apply(nWBV_pred2, 2, mean)
mean(abs(impact))
```

```{r}
MMSE_pred1 <- posterior_linpred(model2, newdata = oasis_model, transform = TRUE)
MMSE_pred2 <- posterior_linpred(model2, newdata = mutate(oasis_model, MMSE = mean(MMSE)), transform = TRUE)

MMSE_impact <- apply(MMSE_pred1, 2, mean) - apply(MMSE_pred2, 2, mean)
mean(abs(impact))
```

| Variable | Impact (avg change in predicted probability) |
|----------|----------------------------------------------|
| nWBV     | 0.000801 (\~0.08%)                           |
| MMSE     | 0.000967 (\~0.097%)                          |

Posterior predictive simulations show that MMSE changes the predicted probability of dementia by only \~0.1%.

```{r}
pred_probs1 <- apply(posterior_linpred(model1, transform = TRUE), 2, mean)
pred_probs2 <- apply(posterior_linpred(model2, transform = TRUE), 2, mean)
pred_probs3 <- apply(posterior_linpred(model3, transform = TRUE), 2, mean
```

**All 3 models:** The x-axis represents the predicted probability of dementia (0 = no dementia, 1 = dementia), and the y-axis represents the density of subjects at each predicted probability. Higher density values indicate that more subjects have predicted probabilities near that x-value.

```{r}
plot(density(pred_probs1), col = "red", lwd = 2, xlab = "Predicted Probability", ylab = "Density")
lines(density(pred_probs2), col = "blue", lwd = 2)
lines(density(pred_probs3), col = "green", lwd = 2)

legend("topleft", legend = c("Model1", "Model2", "Model3"), col = c("red", "blue", "green"), lwd = 2)
```

Model 1 has a taller desity peak showing that the model predicts very similar probabilities for most subjects. This suggests that there is less variation in predicted dementia risk. Lower, wider peaks in Models 2 and 3 would show that adding predictors like nWBV and sex increases differentiation between subjects, although in this case the effect appears minimal. When comparing all three models, posterior predictive simulations revealed nearly identical predicted probability distributions, confirming that adding nWBV or sex did not meaningfully change the model’s predictive behavior

In conclusion, the Bayesian analysis showed that Age and MMSE are the only predictors that consistently matter for identifying dementia in this dataset. Even though we tried adding extra variables like nWBV and sex, the models couldn’t find clear or reliable effects from them. Their coefficients had a lot of uncertainty, and the posterior predictive simulations showed that they barely changed the predicted probability of dementia at all. The posterior predictive density plots backed this up since all three models produced almost the same pattern of predicted probabilities. This means the extra predictors didn’t improve anything in terms of prediction.

Because of this, **Model 1 (Age + MMSE)** turned out to be the strongest and most practical model. It’s simple, easier to interpret, and performs just as well as the more complicated versions. Overall, the Bayesian workflow showed that there really isn’t much additional predictive signal in this dataset beyond Age and MMSE, and adding more predictors doesn’t give you any meaningful benefit. This highlights how important it is to look not just at statistical significance, but also at uncertainty and real-world predictive impact when choosing a model.
